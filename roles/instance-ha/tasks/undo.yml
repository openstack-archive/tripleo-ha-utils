---
- block:
    - name: Remove STONITH level definitions for compute nodes
      shell: |
        compute_stonith_name=$(cibadmin --query --xpath "//primitive[@class='stonith']/instance_attributes/nvpair[@value='{{ item }}']" | sed 's/.*id="\(.*\)-instance_attributes-pcmk_host_list".*/\1/g')
        for stonith_level in $(cibadmin --query --xpath "//configuration/fencing-topology/fencing-level[@devices='$compute_stonith_name,fence-nova'][@index='1'][@target='{{ item }}']" --node-path)
         do
          pcs stonith level delete 1 {{ item }} $compute_stonith_name,fence-nova
         done
      with_items: "{{ groups['compute'] }}"

    - name: Remove fence-nova STONITH device
      shell: |
        for stonithid in $(pcs stonith show | awk '/fence_compute/ {print $1}')
         do
          pcs stonith delete fence-nova
         done

    - name: Remove resources associated to remote nodes
      shell: |
        for resourceid in $(pcs resource show | grep compute | grep 'Clone Set:' | awk '{print $3}')
         do
          pcs resource cleanup $resourceid
          pcs --force resource delete $resourceid
         done

    - name: Remove NovaEvacuate resource
      shell: |
        for resourceid in $(pcs resource show | grep NovaEvacuate | awk '/NovaEvacuate/ {print $1}')
         do
          pcs resource cleanup $resourceid
          pcs --force resource delete $resourceid
         done

    - name: Remove pacemaker remote resource
      shell: |
        for resourceid in $(pcs resource show | awk '/:remote/ {print $1}')
         do
          pcs resource cleanup $resourceid
          pcs --force resource delete $resourceid
         done

    - name: Remove constraints related to role controller
      shell: |
        for constraintid in $(pcs config show | grep -B 3 "osprole eq controller" | awk '/Constraint/ {print $2}')
         do
          pcs constraint delete $constraintid
         done

    - name: Unset controller pacemaker property on controllers
      shell: |
        for nodeid in $(pcs property | awk '/osprole/ { print $1 }' | cut -d: -f1)
         do
          pcs property unset --node $nodeid osprole
         done

    - name: Unset cluster recheck interval to 1 minute
      shell: |
        for propertyid in $(pcs property | awk '/cluster-recheck-interval/ { print $1 }' | cut -d: -f1)
         do
          pcs property unset cluster-recheck-interval
        done
  become: yes
  delegate_to: "{{ groups.controller[0] }}"

- name: Cleanup failed resources (if any)
  shell: |
    for resource in $(pcs status | sed -n -e '/Failed Actions:/,/^$/p' | egrep 'OCF_|not running|unknown' | awk '{print $2}' | cut -f1 -d_ | sort |uniq)
     do
      pcs resource cleanup $resource
     done
  become: yes
  delegate_to: "{{ groups.controller[0] }}"

- name: Wait for failed resources to recover (if any)
  shell: pcs status | sed -n -e '/Failed Actions:/,/^$/p' | egrep 'OCF_|not running|unknown' | awk '{print $2}' | cut -f1 -d_ | sort |uniq
  register: failed_resources
  until: failed_resources.stdout != []
  retries: 10
  delay: 10
  become: yes
  delegate_to: "{{ groups.controller[0] }}"

- name: Enable openstack-nova-compute on compute
  service:
    name: openstack-nova-compute
    state: started
    enabled: yes
  become: yes
  delegate_to: "{{ item }}"
  with_items:
    - "{{ groups['compute'] }}"
  when: release not in [ 'pike', 'rhos-12' ]

- name: Enable neutron-openvswitch-agent on compute
  service:
    name: neutron-openvswitch-agent
    state: started
    enabled: yes
  become: yes
  delegate_to: "{{ item }}"
  with_items:
    - "{{ groups['compute'] }}"
  when: release in [ 'liberty', 'rhos-8', 'mitaka', 'rhos-9' ]

- name: Enable openstack-ceilometer-compute on compute
  service:
    name: openstack-ceilometer-compute
    state: started
    enabled: yes
  become: yes
  delegate_to: "{{ item }}"
  with_items:
    - "{{ groups['compute'] }}"
  when: release in [ 'liberty', 'rhos-8', 'mitaka', 'rhos-9' ]

- name: Enable libvirtd on compute
  become: yes
  service:
    name: libvirtd
    state: started
    enabled: yes
  delegate_to: "{{ item }}"
  with_items:
    - "{{ groups['compute'] }}"
  when: release in [ 'liberty', 'rhos-8', 'mitaka', 'rhos-9' ]

- name: Stop pacemaker remote service on compute nodes
  become: yes
  service:
    name: pacemaker_remote
    enabled: no
    state: stopped
  delegate_to: "{{ item }}"
  with_items:
    - "{{ groups['compute'] }}"

- name: Disable iptables traffic for pacemaker_remote
  become: yes
  shell: |
    while [ $(iptables-save | grep -c "\-A INPUT \-p tcp \-m state \-\-state NEW \-m tcp \-\-dport 3121 \-j ACCEPT") -ne 0 ]
     do
      iptables -D INPUT -p tcp -m state --state NEW -m tcp --dport 3121 -j ACCEPT
     done
  delegate_to: "{{ item }}"
  with_items:
    - "{{ groups['controller'] }}"
    - "{{ groups['compute'] }}"

- name: Remove iptables pacemaker_remote permanent rule
  become: yes
  lineinfile:
    path: /etc/sysconfig/iptables
    line: "-A INPUT -p tcp -m state --state NEW -m tcp --dport 3121 -j ACCEPT"
    state: absent
  delegate_to: "{{ item }}"
  with_items:
    - "{{ groups['controller'] }}"
    - "{{ groups['compute'] }}"

- name: Undo STONITH for compute nodes
  include_role:
    name: stonith-config
  vars:
    stonith_action: "uninstall"
    stonith_devices: "computes"
  when:
    - stonith_devices in ["all","computes"]
